{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning and Tokenization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tokenization splits a sentence into its components\n",
    "Cleaning occurs through the use of regular expressions\n",
    "A regular expression is a set of characters in a given order that represents a pattern\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "sentence = \"Sunil tweeted, 'Witnessing 70th Republic Day of India from Rajpath, \\\n",
    "           New Dehli.  Mesmerizing performance by Indian Army!  Awesome airshow! @india_official \\\n",
    "           @indian_army #India #70thRepublic_Day.  For more photos ping me @sunil@photoking.com :)'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " 'Witnessing',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " 'New',\n",
       " 'Dehli',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " 'india',\n",
       " 'official',\n",
       " 'indian',\n",
       " 'army',\n",
       " 'India',\n",
       " '70thRepublic',\n",
       " 'Day',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil',\n",
       " 'photoking',\n",
       " 'com']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regextext = re.sub(r\"([^\\s\\w]|_)+\", \" \", sentence).split()\n",
    "regextext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of N-Grams ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition of a Function for Extraction\n",
    "import re\n",
    "\n",
    "def n_gram_extractor(sentence, n):\n",
    "    tokens = re.sub(r\"([^\\s\\w]|_)+\", \" \", sentence).split()\n",
    "    for i in range(len(tokens)- n + 1):\n",
    "        print(tokens[i: i + n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cute']\n",
      "['cute', 'little']\n",
      "['little', 'girl']\n",
      "['girl', 'is']\n",
      "['is', 'playing']\n",
      "['playing', 'with']\n",
      "['with', 'the']\n",
      "['the', 'kitten']\n"
     ]
    }
   ],
   "source": [
    "#Extraction of Bi-Grams\n",
    "bgex = n_gram_extractor(\"The cute little girl is playing with the kitten.\", 2)\n",
    "bgex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cute', 'little']\n",
      "['cute', 'little', 'girl']\n",
      "['little', 'girl', 'is']\n",
      "['girl', 'is', 'playing']\n",
      "['is', 'playing', 'with']\n",
      "['playing', 'with', 'the']\n",
      "['with', 'the', 'kitten']\n"
     ]
    }
   ],
   "source": [
    "#Tri-Grams\n",
    "tgex = n_gram_extractor(\"The cute little girl is playing with the kitten.\", 3)\n",
    "tgex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'cute'),\n",
       " ('cute', 'little'),\n",
       " ('little', 'girl'),\n",
       " ('girl', 'is'),\n",
       " ('is', 'playing'),\n",
       " ('playing', 'with'),\n",
       " ('with', 'the'),\n",
       " ('the', 'kitten.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLTK and Bi-Grams\n",
    "from nltk import ngrams\n",
    "bgnltk = list(ngrams(\"The cute little girl is playing with the kitten.\".split(), 2))\n",
    "bgnltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'cute', 'little'),\n",
       " ('cute', 'little', 'girl'),\n",
       " ('little', 'girl', 'is'),\n",
       " ('girl', 'is', 'playing'),\n",
       " ('is', 'playing', 'with'),\n",
       " ('playing', 'with', 'the'),\n",
       " ('with', 'the', 'kitten.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NLTK and Tri-Grams\n",
    "from nltk import ngrams\n",
    "tgnltk = list(ngrams(\"The cute little girl is playing with the kitten.\".split(), 3))\n",
    "tgnltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['The', 'cute']),\n",
       " WordList(['cute', 'little']),\n",
       " WordList(['little', 'girl']),\n",
       " WordList(['girl', 'is']),\n",
       " WordList(['is', 'playing']),\n",
       " WordList(['playing', 'with']),\n",
       " WordList(['with', 'the']),\n",
       " WordList(['the', 'kitten'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TextBlob and Bi-Grams\n",
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"The cute little girl is playing with the kitten.\")\n",
    "bgblob = blob.ngrams(n=2)\n",
    "bgblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['The', 'cute', 'little']),\n",
       " WordList(['cute', 'little', 'girl']),\n",
       " WordList(['little', 'girl', 'is']),\n",
       " WordList(['girl', 'is', 'playing']),\n",
       " WordList(['is', 'playing', 'with']),\n",
       " WordList(['playing', 'with', 'the']),\n",
       " WordList(['with', 'the', 'kitten'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TextBlob and Tri-Grams\n",
    "from textblob import TextBlob\n",
    "blob = TextBlob(\"The cute little girl is playing with the kitten.\")\n",
    "tgblob = blob.ngrams(n=3)\n",
    "tgblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization of Text with Keras and TextBlob ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from textblob import TextBlob\n",
    "sentence = \"Sunil tweeted, 'Witnessing the 70th Republic Day of India from Rajpath, \\\n",
    "           New Dehli.  Mesmerizing performance by the Indian Army!  Awesome airshow!  @india_official \\\n",
    "           @indian_army #India #70thRepublic_Day.  For more photos ping me sunil@photoking.com :)'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sunil',\n",
       " 'tweeted',\n",
       " \"'witnessing\",\n",
       " 'the',\n",
       " '70th',\n",
       " 'republic',\n",
       " 'day',\n",
       " 'of',\n",
       " 'india',\n",
       " 'from',\n",
       " 'rajpath',\n",
       " 'new',\n",
       " 'dehli',\n",
       " 'mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'the',\n",
       " 'indian',\n",
       " 'army',\n",
       " 'awesome',\n",
       " 'airshow',\n",
       " 'india',\n",
       " 'official',\n",
       " 'indian',\n",
       " 'army',\n",
       " 'india',\n",
       " '70threpublic',\n",
       " 'day',\n",
       " 'for',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil',\n",
       " 'photoking',\n",
       " 'com',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization with Keras\n",
    "kerastoken = text_to_word_sequence(sentence)\n",
    "kerastoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Sunil', 'tweeted', \"'Witnessing\", 'the', '70th', 'Republic', 'Day', 'of', 'India', 'from', 'Rajpath', 'New', 'Dehli', 'Mesmerizing', 'performance', 'by', 'the', 'Indian', 'Army', 'Awesome', 'airshow', 'india_official', 'indian_army', 'India', '70thRepublic_Day', 'For', 'more', 'photos', 'ping', 'me', 'sunil', 'photoking.com'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization with TextBlob\n",
    "tbtoken = TextBlob(sentence)\n",
    "blob = tbtoken.words\n",
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization of Text with Various Tokenizers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tweet Tokenizer\n",
    "MWE (Multi-Word Expression) Tokenizer\n",
    "Regular Expression Tokenizer\n",
    "Whitespace Tokenizer\n",
    "Word Punkt Tokenizer\n",
    "\"\"\"\n",
    "\n",
    "sentence = \"Sunil tweeted, 'Witnessing the 70th Republic Day of India from Rajpath, \\\n",
    "           New Dehli.  Mesmerizing performance by the Indian Army!  Awesome airshow!  @india_official \\\n",
    "           @indian_army #India #70thRepublic_Day.  For more photos ping me sunil@photoking.com :)'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted',\n",
       " ',',\n",
       " \"'\",\n",
       " 'Witnessing',\n",
       " 'the',\n",
       " '70th',\n",
       " 'Republic',\n",
       " 'Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath',\n",
       " ',',\n",
       " 'New',\n",
       " 'Dehli',\n",
       " '.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Army',\n",
       " '!',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '!',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day',\n",
       " '.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " ':)',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tweet Tokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "tttoken = tweet_tokenizer.tokenize(sentence)\n",
    "tttoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sunil',\n",
       " 'tweeted,',\n",
       " \"'Witnessing\",\n",
       " 'the',\n",
       " '70th',\n",
       " 'Republic_Day',\n",
       " 'of',\n",
       " 'India',\n",
       " 'from',\n",
       " 'Rajpath,',\n",
       " 'New',\n",
       " 'Dehli.',\n",
       " 'Mesmerizing',\n",
       " 'performance',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Indian_Army',\n",
       " 'Awesome',\n",
       " 'airshow',\n",
       " '@india_official',\n",
       " '@indian_army',\n",
       " '#India',\n",
       " '#70thRepublic_Day.',\n",
       " 'For',\n",
       " 'more',\n",
       " 'photos',\n",
       " 'ping',\n",
       " 'me',\n",
       " 'sunil@photoking.com',\n",
       " \":)'\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MWE (Multi-Word Expression) Tokenizer\n",
    "from nltk.tokenize import MWETokenizer\n",
    "mwe_tokenizer = MWETokenizer([(\"Republic\", \"Day\")])\n",
    "mwe_tokenizer.add_mwe((\"Indian\", \"Army\"))\n",
    "mwetoken = mwe_tokenizer.tokenize(sentence.replace(\"!\", \"\").split())\n",
    "mwetoken"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pandas] *",
   "language": "python",
   "name": "conda-env-pandas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
